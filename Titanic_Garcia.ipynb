{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del DataSet al ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"data_titanic_proyecto.csv\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PassengerId                                               Name   Age  \\\n",
      "0             1                            Braund, Mr. Owen Harris  22.0   \n",
      "1             2  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0   \n",
      "2             3                             Heikkinen, Miss. Laina  26.0   \n",
      "3             4       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0   \n",
      "4             5                           Allen, Mr. William Henry  35.0   \n",
      "5             6                                   Moran, Mr. James   NaN   \n",
      "6             7                            McCarthy, Mr. Timothy J  54.0   \n",
      "7             8                     Palsson, Master. Gosta Leonard   2.0   \n",
      "8             9  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  27.0   \n",
      "9            10                Nasser, Mrs. Nicholas (Adele Achem)  14.0   \n",
      "10           11                    Sandstrom, Miss. Marguerite Rut   4.0   \n",
      "\n",
      "    SibSp  Parch            Ticket     Fare Cabin Embarked passenger_class  \\\n",
      "0       1      0         A/5 21171   7.2500   NaN        S           Lower   \n",
      "1       1      0          PC 17599  71.2833   C85        C           Upper   \n",
      "2       0      0  STON/O2. 3101282   7.9250   NaN        S           Lower   \n",
      "3       1      0            113803  53.1000  C123        S           Upper   \n",
      "4       0      0            373450   8.0500   NaN        S           Lower   \n",
      "5       0      0            330877   8.4583   NaN        Q           Lower   \n",
      "6       0      0             17463  51.8625   E46        S           Upper   \n",
      "7       3      1            349909  21.0750   NaN        S           Lower   \n",
      "8       0      2            347742  11.1333   NaN        S           Lower   \n",
      "9       1      0            237736  30.0708   NaN        C          Middle   \n",
      "10      1      1           PP 9549  16.7000    G6        S           Lower   \n",
      "\n",
      "   passenger_sex passenger_survived  \n",
      "0              M                  N  \n",
      "1              F                  Y  \n",
      "2              F                  Y  \n",
      "3              F                  Y  \n",
      "4              M                  N  \n",
      "5              M                  N  \n",
      "6              M                  N  \n",
      "7              M                  N  \n",
      "8              F                  Y  \n",
      "9              F                  Y  \n",
      "10             F                  Y  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "#print(dataset)\n",
    "print(dataset.loc[0:10])\n",
    "\n",
    "print(type(dataset))\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separacion de variables [x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dataset[\"passenger_survived\"]\n",
    "x=dataset[[\"passenger_class\",\"passenger_sex\",\"Age\",\"SibSp\",\"Parch\",\"Embarked\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separar el DataSet en Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Slicing al dataset 80% / 20%\n",
    "\n",
    "df_train, df_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recorrido y Analisis de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos:\n",
      "(712, 6)\n",
      "(179, 6)\n",
      "Tipos de datos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 301 to 37\n",
      "Data columns (total 6 columns):\n",
      "passenger_class    712 non-null object\n",
      "passenger_sex      712 non-null object\n",
      "Age                568 non-null float64\n",
      "SibSp              712 non-null int64\n",
      "Parch              712 non-null int64\n",
      "Embarked           710 non-null object\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 38.9+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179 entries, 862 to 448\n",
      "Data columns (total 6 columns):\n",
      "passenger_class    179 non-null object\n",
      "passenger_sex      179 non-null object\n",
      "Age                146 non-null float64\n",
      "SibSp              179 non-null int64\n",
      "Parch              179 non-null int64\n",
      "Embarked           179 non-null object\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 9.8+ KB\n",
      "None\n",
      "Datos faltantes:\n",
      "passenger_class      0\n",
      "passenger_sex        0\n",
      "Age                144\n",
      "SibSp                0\n",
      "Parch                0\n",
      "Embarked             2\n",
      "dtype: int64\n",
      "passenger_class     0\n",
      "passenger_sex       0\n",
      "Age                33\n",
      "SibSp               0\n",
      "Parch               0\n",
      "Embarked            0\n",
      "dtype: int64\n",
      "Estadísticas del dataset:\n",
      "              Age       SibSp       Parch\n",
      "count  568.000000  712.000000  712.000000\n",
      "mean    30.166232    0.494382    0.370787\n",
      "std     14.856398    1.010478    0.775968\n",
      "min      0.420000    0.000000    0.000000\n",
      "25%     20.000000    0.000000    0.000000\n",
      "50%     29.000000    0.000000    0.000000\n",
      "75%     39.000000    1.000000    0.000000\n",
      "max     80.000000    8.000000    6.000000\n",
      "              Age       SibSp       Parch\n",
      "count  146.000000  179.000000  179.000000\n",
      "mean    27.881849    0.636872    0.424581\n",
      "std     13.053345    1.409033    0.917164\n",
      "min      0.750000    0.000000    0.000000\n",
      "25%     21.000000    0.000000    0.000000\n",
      "50%     27.000000    0.000000    0.000000\n",
      "75%     35.000000    1.000000    0.000000\n",
      "max     61.000000    8.000000    5.000000\n"
     ]
    }
   ],
   "source": [
    "#Verifico la cantidad de datos que hay en los dataset\n",
    "print('Cantidad de datos:')\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "#Verifico el tipo de datos contenida en ambos dataset\n",
    "print('Tipos de datos:')\n",
    "print(df_train.info())\n",
    "print(df_test.info())\n",
    "\n",
    "#Verifico los datos faltantes de los dataset\n",
    "print('Datos faltantes:')\n",
    "print(pd.isnull(df_train).sum())\n",
    "print(pd.isnull(df_test).sum())\n",
    "\n",
    "#Verifico las estadísticas del dataset\n",
    "print('Estadísticas del dataset:')\n",
    "print(df_train.describe())\n",
    "print(df_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_class    0\n",
      "passenger_sex      0\n",
      "Age                0\n",
      "SibSp              0\n",
      "Parch              0\n",
      "Embarked           0\n",
      "dtype: int64\n",
      "passenger_class    0\n",
      "passenger_sex      0\n",
      "Age                0\n",
      "SibSp              0\n",
      "Parch              0\n",
      "Embarked           0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coke Garcia\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Coke Garcia\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Se elimina las filas con los datos perdidos\n",
    "df_train.dropna(axis=0, how='any', inplace=True)\n",
    "df_test.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "#Verifico los datos\n",
    "print(pd.isnull(df_train).sum())\n",
    "print(pd.isnull(df_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambio los datos de sexos en números\n",
    ">>> le = preprocessing.LabelEncoder()\n",
    ">>> le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
    "LabelEncoder()\n",
    ">>> list(le.classes_)\n",
    "['amsterdam', 'paris', 'tokyo']\n",
    ">>> le.transform([\"tokyo\", \"tokyo\", \"paris\"]) \n",
    "array([2, 2, 1]...)\n",
    ">>> list(le.inverse_transform([2, 2, 1]))\n",
    "['tokyo', 'tokyo', 'paris']\n",
    "\n",
    "#Cambio los datos de embarque en números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot compare types 'ndarray(dtype=int64)' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-00315cf13744>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Cambio los datos de sexos en números\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'passenger_sex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'M'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'passenger_sex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'M'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Cambio los datos de embarque en números\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   3430\u001b[0m         return super(Series, self).replace(to_replace=to_replace, value=value,\n\u001b[0;32m   3431\u001b[0m                                            \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3432\u001b[1;33m                                            regex=regex, method=method)\n\u001b[0m\u001b[0;32m   3433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3434\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shift'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   5849\u001b[0m                                                        \u001b[0mdest_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5850\u001b[0m                                                        \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5851\u001b[1;33m                                                        regex=regex)\n\u001b[0m\u001b[0;32m   5852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5853\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# [NA, ''] -> 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mreplace_list\u001b[1;34m(self, src_list, dest_list, inplace, regex, mgr)\u001b[0m\n\u001b[0;32m   3737\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_maybe_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'asm8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3739\u001b[1;33m         \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3741\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3737\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_maybe_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'asm8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3739\u001b[1;33m         \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3741\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mcomp\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m   3735\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3736\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3737\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_maybe_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'asm8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_maybe_compare\u001b[1;34m(a, b, op)\u001b[0m\n\u001b[0;32m   5163\u001b[0m         raise TypeError(\n\u001b[0;32m   5164\u001b[0m             \"Cannot compare types {a!r} and {b!r}\".format(a=type_names[0],\n\u001b[1;32m-> 5165\u001b[1;33m                                                           b=type_names[1]))\n\u001b[0m\u001b[0;32m   5166\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot compare types 'ndarray(dtype=int64)' and 'str'"
     ]
    }
   ],
   "source": [
    "#Cambio los datos de sexos en números\n",
    "df_train['passenger_sex'].replace(['F','M'],[0,1],inplace=True)\n",
    "df_test['passenger_sex'].replace(['F','M'],[0,1],inplace=True)\n",
    "\n",
    "#Cambio los datos de embarque en números\n",
    "df_train['Embarked'].replace(['Q','S','C'],[0,1,2],inplace=True)\n",
    "df_test['Embarked'].replace(['Q','S','C'],[0,1,2],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reemplazo los datos faltantes en la edad por la media de esta columna\n",
    "print(df_train[\"Age\"].mean())\n",
    "print(df_test[\"Age\"].mean())\n",
    "promedio = 30\n",
    "df_train['Age'] = df_train['Age'].replace(np.nan, promedio)\n",
    "df_test['Age'] = df_test['Age'].replace(np.nan, promedio)\n",
    "\n",
    "#Creo varios grupos de acuerdo a bandas de las edades\n",
    "#Bandas: 0-8, 9-15, 16-18, 19-25, 26-40, 41-60, 61-100\n",
    "bins = [0, 8, 15, 18, 25, 40, 60, 100]\n",
    "names = ['1', '2', '3', '4', '5', '6', '7']\n",
    "df_train['Age'] = pd.cut(df_train['Age'], bins, labels = names)\n",
    "df_test['Age'] = pd.cut(df_test['Age'], bins, labels = names)\n",
    "\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "print(df_test.head())\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacion de los Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Survived'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-7e9ea8f8e387>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Separo la columna con la información de los sobrevivientes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Separo los datos de \"train\" en entrenamiento y prueba para probar los algoritmos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3697\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3110\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3111\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3141\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3142\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3143\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3144\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4403\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4404\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4405\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4406\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Survived'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#Separo la columna con la información de los sobrevivientes\n",
    "x = np.array(df_train.drop(['Survived'], 1))\n",
    "y = np.array(df_train['Survived'])\n",
    "\n",
    "#Separo los datos de \"train\" en entrenamiento y prueba para probar los algoritmos\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "##Regresión logística\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "Y_pred = logreg.predict(x_test)\n",
    "print('Precisión Regresión Logística:')\n",
    "print(logreg.score(x_train, y_train))\n",
    "\n",
    "##Support Vector Machines\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)\n",
    "Y_pred = svc.predict(x_test)\n",
    "print('Precisión Soporte de Vectores:')\n",
    "print(svc.score(x_train, y_train))\n",
    "\n",
    "##K neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train, y_train)\n",
    "Y_pred = knn.predict(x_test)\n",
    "print('Precisión Vecinos más Cercanos:')\n",
    "print(knn.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediccion de los Datos [df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df_test['PassengerId']\n",
    "\n",
    "##Regresión logística\n",
    "prediccion_logreg = logreg.predict(df_test.drop('PassengerId', axis=1))\n",
    "out_logreg = pd.DataFrame({ 'PassengerId' : ids, 'Survived': prediccion_logreg })\n",
    "print('Predicción Regresión Logística:')\n",
    "print(out_logreg.head())\n",
    "\n",
    "##Support Vector Machines\n",
    "prediccion_svc = svc.predict(df_test.drop('PassengerId', axis=1))\n",
    "out_svc = pd.DataFrame({ 'PassengerId' : ids, 'Survived': prediccion_svc })\n",
    "print('Predicción Soporte de Vectores:')\n",
    "print(out_svc.head())\n",
    "\n",
    "##K neighbors\n",
    "prediccion_knn = knn.predict(df_test.drop('PassengerId', axis=1))\n",
    "out_knn = pd.DataFrame({ 'PassengerId' : ids, 'Survived': prediccion_knn })\n",
    "print('Predicción Vecinos más Cercanos:')\n",
    "print(out_knn.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: \n",
    "Entrenamiento y validación y selección (Nivel de exactitud mínimo deseado: 80%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: \n",
    "En los casos en donde se deba calcular métricas de evaluación,con objetivos de simplificar el problema se puede usar cualquier herramienta , por ejemplo sklearn en el subpaquete metrics:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "- https://scikit-learn.org/stable/modules/model_evaluation.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_sex ['F' 'M']\n"
     ]
    }
   ],
   "source": [
    "print(\"passenger_sex\", np.unique(dataset[\"passenger_sex\"]))\n",
    "#print(\"Age\", np.unique(dataset[\"Age\"]))\n",
    "#print(\"PassengerId\", np.unique(dataset[\"PassengerId\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##One-Hot\n",
    "with tf.Session() as sesh:\n",
    "    y_train = sesh.run(tf.one_hot(y_train, 3))\n",
    "    y_test = sesh.run(tf.one_hot(y_test, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-val-test split \n",
    "El primer paso es separar los datos en entrenamiento, validación y pruebas:\n",
    "\n",
    "- separar datos en entrenamiento y pruebas. Por ejemplo usando: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- tomar una porción de datos de entrenamiento del paso anterior para validación. Puede ser aplicando nuevamente https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "Esto genera en resumen:\n",
    "1.\tConjunto de entrenamiento \n",
    "2.\tConjunto de validación\n",
    "3.\tConjunto de pruebas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
