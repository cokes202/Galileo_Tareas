{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.08500e+05 7.00000e+00 8.56000e+02 8.00000e+00 2.00300e+03 6.50000e+01]\n",
      " [1.81500e+05 6.00000e+00 1.26200e+03 6.00000e+00 1.97600e+03 8.00000e+01]\n",
      " [2.23500e+05 7.00000e+00 9.20000e+02 6.00000e+00 2.00100e+03 6.80000e+01]\n",
      " ...\n",
      " [2.66500e+05 7.00000e+00 1.18800e+03 9.00000e+00 1.94100e+03 6.60000e+01]\n",
      " [1.42125e+05 5.00000e+00 1.07800e+03 5.00000e+00 1.95000e+03 6.80000e+01]\n",
      " [1.47500e+05 5.00000e+00 1.25600e+03 6.00000e+00 1.96500e+03 7.50000e+01]]\n",
      "<class 'numpy.ndarray'>\n",
      "(1460, 6)\n"
     ]
    }
   ],
   "source": [
    "## Importar datos desde el dataset.\n",
    "dataset = \"proyecto_training_data.npy\"\n",
    "data = np.load(dataset)\n",
    "print(data) \n",
    "print(type(data))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80% de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0850e+05 7.0000e+00 8.5600e+02 8.0000e+00 2.0030e+03 6.5000e+01]\n",
      " [1.8150e+05 6.0000e+00 1.2620e+03 6.0000e+00 1.9760e+03 8.0000e+01]\n",
      " [2.2350e+05 7.0000e+00 9.2000e+02 6.0000e+00 2.0010e+03 6.8000e+01]\n",
      " ...\n",
      " [2.3317e+05 7.0000e+00 1.5020e+03 7.0000e+00 2.0090e+03 7.9000e+01]\n",
      " [2.4535e+05 8.0000e+00 1.6940e+03 7.0000e+00 2.0080e+03 6.4000e+01]\n",
      " [1.7300e+05 6.0000e+00 9.5900e+02 7.0000e+00 2.0000e+03 5.8000e+01]]\n",
      "(Filas , Columnas) = (1168, 6)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "## Slicing al dataset\n",
    "trainingdata = data [:1168,]\n",
    "\n",
    "print(trainingdata)\n",
    "print(\"(Filas , Columnas) =\", trainingdata.shape) \n",
    "print(type(trainingdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20% de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.35000e+05 6.00000e+00 1.23600e+03 7.00000e+00 1.93500e+03 1.20000e+02]\n",
      " [6.25000e+05 1.00000e+01 1.83100e+03 1.00000e+01 1.99500e+03 1.18000e+02]\n",
      " [1.71000e+05 6.00000e+00 1.11800e+03 6.00000e+00 1.97700e+03 7.60000e+01]\n",
      " ...\n",
      " [2.66500e+05 7.00000e+00 1.18800e+03 9.00000e+00 1.94100e+03 6.60000e+01]\n",
      " [1.42125e+05 5.00000e+00 1.07800e+03 5.00000e+00 1.95000e+03 6.80000e+01]\n",
      " [1.47500e+05 5.00000e+00 1.25600e+03 6.00000e+00 1.96500e+03 7.50000e+01]]\n",
      "(Filas , Columnas) = (292, 6)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "## Slicing al dataset \n",
    "dataprueba = data [1168:,]\n",
    "\n",
    "print(dataprueba)\n",
    "print(\"(Filas , Columnas) =\", dataprueba.shape)\n",
    "print(type(dataprueba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de los datos por Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208500. 181500. 223500. ... 233170. 245350. 173000.] de tipo  <class 'numpy.ndarray'> de rango  1 de la forma  (1168,)\n",
      "[7. 6. 7. ... 7. 8. 6.] de tipo  <class 'numpy.ndarray'> de rango  1 de la forma  (1168,)\n"
     ]
    }
   ],
   "source": [
    "# Extracción por columnas del 80%\n",
    "\n",
    "saleprice=trainingdata[:,0]\n",
    "quality=trainingdata[:,1]\n",
    "\n",
    "print(saleprice,\"de tipo \", type(saleprice),\"de rango \",saleprice.ndim, \"de la forma \",saleprice.shape)\n",
    "print(quality,\"de tipo \", type(quality),\"de rango \",quality.ndim, \"de la forma \",quality.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracción por Columnas del 20%\n",
    "\n",
    "saleprice20=dataprueba[:,0]\n",
    "quality20=dataprueba[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Las dos variables con mayor poder predictivo (Mayor correlación)\n",
    "1. La variable Quality tiene un coeficiente de correlación de 0.79\n",
    "2. La variable Square Feet tiene un coeficiente de correlación de 0.61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que cada extracción de columna era un vector de 1168 filas, ahora lo convertiremos en una matriz de (1168,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[208500.]\n",
      " [181500.]\n",
      " [223500.]\n",
      " ...\n",
      " [233170.]\n",
      " [245350.]\n",
      " [173000.]] de tipo  <class 'numpy.ndarray'> de rango  2 de la forma  (1168, 1)\n",
      "[[7.]\n",
      " [6.]\n",
      " [7.]\n",
      " ...\n",
      " [7.]\n",
      " [8.]\n",
      " [6.]] de tipo  <class 'numpy.ndarray'> de rango  2 de la forma  (1168, 1)\n"
     ]
    }
   ],
   "source": [
    "saleprice=np.reshape(saleprice,(1168,1)) \n",
    "quality=np.reshape(quality,(1168,1)) \n",
    "\n",
    "print(saleprice,\"de tipo \", type(saleprice),\"de rango \",saleprice.ndim, \"de la forma \",saleprice.shape)\n",
    "print(quality,\"de tipo \", type(quality),\"de rango \",quality.ndim, \"de la forma \",quality.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que cada extracción de columna era un vector de 292 filas, ahora lo convertiremos en una matriz de (292,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[235000.]\n",
      " [625000.]\n",
      " [171000.]\n",
      " [163000.]\n",
      " [171900.]\n",
      " [200500.]\n",
      " [239000.]\n",
      " [285000.]\n",
      " [119500.]\n",
      " [115000.]\n",
      " [154900.]\n",
      " [ 93000.]\n",
      " [250000.]\n",
      " [392500.]\n",
      " [745000.]\n",
      " [120000.]\n",
      " [186700.]\n",
      " [104900.]\n",
      " [ 95000.]\n",
      " [262000.]\n",
      " [195000.]\n",
      " [189000.]\n",
      " [168000.]\n",
      " [174000.]\n",
      " [125000.]\n",
      " [165000.]\n",
      " [158000.]\n",
      " [176000.]\n",
      " [219210.]\n",
      " [144000.]\n",
      " [178000.]\n",
      " [148000.]\n",
      " [116050.]\n",
      " [197900.]\n",
      " [117000.]\n",
      " [213000.]\n",
      " [153500.]\n",
      " [271900.]\n",
      " [107000.]\n",
      " [200000.]\n",
      " [140000.]\n",
      " [290000.]\n",
      " [189000.]\n",
      " [164000.]\n",
      " [113000.]\n",
      " [145000.]\n",
      " [134500.]\n",
      " [125000.]\n",
      " [112000.]\n",
      " [229456.]\n",
      " [ 80500.]\n",
      " [ 91500.]\n",
      " [115000.]\n",
      " [134000.]\n",
      " [143000.]\n",
      " [137900.]\n",
      " [184000.]\n",
      " [145000.]\n",
      " [214000.]\n",
      " [147000.]\n",
      " [367294.]\n",
      " [127000.]\n",
      " [190000.]\n",
      " [132500.]\n",
      " [101800.]\n",
      " [142000.]\n",
      " [130000.]\n",
      " [138887.]\n",
      " [175500.]\n",
      " [195000.]\n",
      " [142500.]\n",
      " [265900.]\n",
      " [224900.]\n",
      " [248328.]\n",
      " [170000.]\n",
      " [465000.]\n",
      " [230000.]\n",
      " [178000.]\n",
      " [186500.]\n",
      " [169900.]\n",
      " [129500.]\n",
      " [119000.]\n",
      " [244000.]\n",
      " [171750.]\n",
      " [130000.]\n",
      " [294000.]\n",
      " [165400.]\n",
      " [127500.]\n",
      " [301500.]\n",
      " [ 99900.]\n",
      " [190000.]\n",
      " [151000.]\n",
      " [181000.]\n",
      " [128900.]\n",
      " [161500.]\n",
      " [180500.]\n",
      " [181000.]\n",
      " [183900.]\n",
      " [122000.]\n",
      " [378500.]\n",
      " [381000.]\n",
      " [144000.]\n",
      " [260000.]\n",
      " [185750.]\n",
      " [137000.]\n",
      " [177000.]\n",
      " [139000.]\n",
      " [137000.]\n",
      " [162000.]\n",
      " [197900.]\n",
      " [237000.]\n",
      " [ 68400.]\n",
      " [227000.]\n",
      " [180000.]\n",
      " [150500.]\n",
      " [139000.]\n",
      " [169000.]\n",
      " [132500.]\n",
      " [143000.]\n",
      " [190000.]\n",
      " [278000.]\n",
      " [281000.]\n",
      " [180500.]\n",
      " [119500.]\n",
      " [107500.]\n",
      " [162900.]\n",
      " [115000.]\n",
      " [138500.]\n",
      " [155000.]\n",
      " [140000.]\n",
      " [160000.]\n",
      " [154000.]\n",
      " [225000.]\n",
      " [177500.]\n",
      " [290000.]\n",
      " [232000.]\n",
      " [130000.]\n",
      " [325000.]\n",
      " [202500.]\n",
      " [138000.]\n",
      " [147000.]\n",
      " [179200.]\n",
      " [335000.]\n",
      " [203000.]\n",
      " [302000.]\n",
      " [333168.]\n",
      " [119000.]\n",
      " [206900.]\n",
      " [295493.]\n",
      " [208900.]\n",
      " [275000.]\n",
      " [111000.]\n",
      " [156500.]\n",
      " [ 72500.]\n",
      " [190000.]\n",
      " [ 82500.]\n",
      " [147000.]\n",
      " [ 55000.]\n",
      " [ 79000.]\n",
      " [130500.]\n",
      " [256000.]\n",
      " [176500.]\n",
      " [227000.]\n",
      " [132500.]\n",
      " [100000.]\n",
      " [125500.]\n",
      " [125000.]\n",
      " [167900.]\n",
      " [135000.]\n",
      " [ 52500.]\n",
      " [200000.]\n",
      " [128500.]\n",
      " [123000.]\n",
      " [155000.]\n",
      " [228500.]\n",
      " [177000.]\n",
      " [155835.]\n",
      " [108500.]\n",
      " [262500.]\n",
      " [283463.]\n",
      " [215000.]\n",
      " [122000.]\n",
      " [200000.]\n",
      " [171000.]\n",
      " [134900.]\n",
      " [410000.]\n",
      " [235000.]\n",
      " [170000.]\n",
      " [110000.]\n",
      " [149900.]\n",
      " [177500.]\n",
      " [315000.]\n",
      " [189000.]\n",
      " [260000.]\n",
      " [104900.]\n",
      " [156932.]\n",
      " [144152.]\n",
      " [216000.]\n",
      " [193000.]\n",
      " [127000.]\n",
      " [144000.]\n",
      " [232000.]\n",
      " [105000.]\n",
      " [165500.]\n",
      " [274300.]\n",
      " [466500.]\n",
      " [250000.]\n",
      " [239000.]\n",
      " [ 91000.]\n",
      " [117000.]\n",
      " [ 83000.]\n",
      " [167500.]\n",
      " [ 58500.]\n",
      " [237500.]\n",
      " [157000.]\n",
      " [112000.]\n",
      " [105000.]\n",
      " [125500.]\n",
      " [250000.]\n",
      " [136000.]\n",
      " [377500.]\n",
      " [131000.]\n",
      " [235000.]\n",
      " [124000.]\n",
      " [123000.]\n",
      " [163000.]\n",
      " [246578.]\n",
      " [281213.]\n",
      " [160000.]\n",
      " [137500.]\n",
      " [138000.]\n",
      " [137450.]\n",
      " [120000.]\n",
      " [193000.]\n",
      " [193879.]\n",
      " [282922.]\n",
      " [105000.]\n",
      " [275000.]\n",
      " [133000.]\n",
      " [112000.]\n",
      " [125500.]\n",
      " [215000.]\n",
      " [230000.]\n",
      " [140000.]\n",
      " [ 90000.]\n",
      " [257000.]\n",
      " [207000.]\n",
      " [175900.]\n",
      " [122500.]\n",
      " [340000.]\n",
      " [124000.]\n",
      " [223000.]\n",
      " [179900.]\n",
      " [127500.]\n",
      " [136500.]\n",
      " [274970.]\n",
      " [144000.]\n",
      " [142000.]\n",
      " [271000.]\n",
      " [140000.]\n",
      " [119000.]\n",
      " [182900.]\n",
      " [192140.]\n",
      " [143750.]\n",
      " [ 64500.]\n",
      " [186500.]\n",
      " [160000.]\n",
      " [174000.]\n",
      " [120500.]\n",
      " [394617.]\n",
      " [149700.]\n",
      " [197000.]\n",
      " [191000.]\n",
      " [149300.]\n",
      " [310000.]\n",
      " [121000.]\n",
      " [179600.]\n",
      " [129000.]\n",
      " [157900.]\n",
      " [240000.]\n",
      " [112000.]\n",
      " [ 92000.]\n",
      " [136000.]\n",
      " [287090.]\n",
      " [145000.]\n",
      " [ 84500.]\n",
      " [185000.]\n",
      " [175000.]\n",
      " [210000.]\n",
      " [266500.]\n",
      " [142125.]\n",
      " [147500.]] de tipo  <class 'numpy.ndarray'> de rango  2 de la forma  (292, 1)\n",
      "[[ 6.]\n",
      " [10.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 9.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 9.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 9.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 3.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [10.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]] de tipo  <class 'numpy.ndarray'> de rango  2 de la forma  (292, 1)\n"
     ]
    }
   ],
   "source": [
    "# Extracción por Columnas del 20%\n",
    "\n",
    "saleprice20=np.reshape(saleprice20,(292,1)) \n",
    "quality20=np.reshape(quality20,(292,1)) \n",
    "\n",
    "print(saleprice20,\"de tipo \", type(saleprice20),\"de rango \",saleprice20.ndim, \"de la forma \",saleprice20.shape)\n",
    "print(quality20,\"de tipo \", type(quality20),\"de rango \",quality20.ndim, \"de la forma \",quality20.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del Gráfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafoInicial = tf.Graph()\n",
    "with grafoInicial.as_default():\n",
    "    # cargando datos como constantes \n",
    "    trainingY = tf.constant(saleprice)\n",
    "    trainingX = tf.constant(quality)\n",
    "    pruebaY = tf.constant(saleprice20)\n",
    "    pruebaX = tf.constant(quality20)\n",
    "    \n",
    "    #placeholder:\n",
    "    ph_learningrate = tf.placeholder(dtype = tf.float64)    \n",
    "  \n",
    "    #Parametros beta1 y beta2:\n",
    "    #Variables\n",
    "    #Estimadores = tf.Variable(np.array([[0],[0]]))\n",
    "    est0 = tf.Variable(0.0, name = \"b0\", dtype = tf.float64)\n",
    "    est1 = tf.Variable(0.0, name = \"b1\", dtype = tf.float64)     \n",
    "    \n",
    "    #Parte de Entrenamiento\n",
    "    #yhat = tf.matmul(trainingX, estimadores)\n",
    "    #Hipotesis\n",
    "    yhat = tf.add(tf.multiply(trainingX, est1), est0)\n",
    "    \n",
    "    #Costo\n",
    "    error = (tf.reduce_mean(tf.pow(trainingY-yhat,2)))*.5\n",
    "    \n",
    "    ##para tensorboard\n",
    "    Summary1st = tf.summary.scalar(name='1st._Summary_Escalar', tensor=error)\n",
    "    \n",
    "    # gradient descent un nodo mas del grafo\n",
    "    optimizador = tf.train.GradientDescentOptimizer(ph_learningrate).minimize(error) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-97-f0ea5e034912>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-97-f0ea5e034912>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    <img src=\"GRAFO.PNG\">\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<img src=\"GRAFO.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primera Sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializado\n",
      "Iteracion: 0 Error: 19409722053.22175 Beta1: 11879476.738013685 Beta0: 1805902.7739726028\n",
      "Iteracion: 2 Error: 4.5991659790119325e+20 Beta1: 1892177310679.6533 Beta0: 295456331982.5073\n",
      "Iteracion: 4 Error: 1.1741538548192451e+31 Beta1: 3.02332463745082e+17 Beta0: 4.720808510516164e+16\n",
      "Iteracion: 6 Error: 2.9975810420448657e+41 Beta1: 4.830674176285755e+22 Beta0: 7.542917317082002e+21\n",
      "Iteracion: 8 Error: 7.652738239325503e+51 Beta1: 7.718460898434383e+27 Beta0: 1.2052088434742129e+27\n",
      "Iteracion: 10 Error: 1.9537220758403224e+62 Beta1: 1.2332572321502991e+33 Beta0: 1.925685110055494e+32\n",
      "Iteracion: 12 Error: 4.987796302781102e+72 Beta1: 1.970500881800828e+38 Beta0: 3.076863535451501e+37\n",
      "Iteracion: 14 Error: 1.2733700594203426e+83 Beta1: 3.148470265532254e+43 Beta0: 4.9162187350133154e+42\n",
      "Iteracion: 16 Error: 3.250877160568992e+93 Beta1: 5.030632112116291e+48 Beta0: 7.855144166135146e+47\n",
      "Iteracion: 18 Error: 8.299395949296999e+103 Beta1: 8.037954089802256e+53 Beta0: 1.2550965121083018e+53\n"
     ]
    }
   ],
   "source": [
    "# epochs \n",
    "num_steps = 20\n",
    "\n",
    "with tf.Session(graph = grafoInicial) as session:\n",
    "    #Inicilizacion de variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Inicializado')\n",
    "    writer = tf.summary.FileWriter('./graphs', session.graph)\n",
    "    for step in range(num_steps): \n",
    "        # sesion que ejecuta los nodos y envia informacion con feed_dict al nodo del learning rate\n",
    "        er, opti = session.run([error, optimizador],feed_dict={ph_learningrate:10.0})\n",
    "        summary = session.run(Summary1st)\n",
    "        writer.add_summary(summary, step)\n",
    "        if (step % 2 == 0):\n",
    "            print(\"Iteracion:\", step, \"Error:\", er, \"Beta1:\", session.run(est1), \"Beta0:\", session.run(est0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda Sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializado\n",
      "Iteracion: 0 Error: 19409722053.22175 Beta1: 2375895.347602737 Beta0: 361180.55479452055\n",
      "Iteracion: 2 Error: 7.068508421135425e+17 Beta1: 14687549353.670645 Beta0: 2293379256.672861\n",
      "Iteracion: 4 Error: 2.7734631500773237e+25 Beta1: 92001657821379.4 Beta0: 14365715233441.164\n",
      "Iteracion: 6 Error: 1.0882207957947e+33 Beta1: 5.762924945647579e+17 Beta0: 8.998592077051824e+16\n",
      "Iteracion: 8 Error: 4.26984039923888e+40 Beta1: 3.6098592925977763e+21 Beta0: 5.6366604694711645e+20\n",
      "Iteracion: 10 Error: 1.6753527506022846e+48 Beta1: 2.261192751121447e+25 Beta0: 3.5307680330468105e+24\n",
      "Iteracion: 12 Error: 6.573563825596209e+55 Beta1: 1.4163966634956459e+29 Beta0: 2.2116504924687565e+28\n",
      "Iteracion: 14 Error: 2.579262269014906e+63 Beta1: 8.872218024609433e+32 Beta0: 1.3853637098374771e+32\n",
      "Iteracion: 16 Error: 1.0120224019823023e+71 Beta1: 5.557500572045525e+36 Beta0: 8.677829589576449e+35\n",
      "Iteracion: 18 Error: 3.970861569285819e+78 Beta1: 3.4811827800688027e+40 Beta0: 5.4357369007856226e+39\n"
     ]
    }
   ],
   "source": [
    "# epochs \n",
    "num_steps = 20\n",
    "\n",
    "with tf.Session(graph = grafoInicial) as session2:\n",
    "    #Inicilizacion de variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Inicializado')\n",
    "    writer = tf.summary.FileWriter('./graphs2', session2.graph)\n",
    "    for step in range(num_steps): \n",
    "        # sesion que ejecuta los nodos y envia informacion con feed_dict al nodo del learning rate\n",
    "        er, opti = session2.run([error, optimizador],feed_dict={ph_learningrate:2.0})\n",
    "        summary = session2.run(Summary1st)\n",
    "        writer.add_summary(summary, step)\n",
    "        if (step % 2 == 0):\n",
    "            print(\"Iteracion:\", step, \"Error:\", er, \"Beta1:\", session2.run(est1), \"Beta0:\", session2.run(est0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tercera Sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializado\n",
      "Iteracion: 0 Error: 19409722053.22175 Beta1: 475179.06952054746 Beta0: 72236.11095890412\n",
      "Iteracion: 2 Error: 919083289664173.4 Beta1: 100600442.13487808 Beta0: 15702610.085544482\n",
      "Iteracion: 4 Error: 4.6889465404191195e+19 Beta1: 22715865980.67634 Beta0: 3546988194.733801\n",
      "Iteracion: 6 Error: 2.3921937036475336e+24 Beta1: 5130849043962.852 Beta0: 801162903271.941\n",
      "Iteracion: 8 Error: 1.2204427298557604e+29 Beta1: 1158910147336838.0 Beta0: 180959491356535.38\n",
      "Iteracion: 10 Error: 6.226420772643428e+33 Beta1: 2.6176422777026896e+17 Beta0: 4.087350656628539e+16\n",
      "Iteracion: 12 Error: 3.1765780310385773e+38 Beta1: 5.912495554509265e+19 Beta0: 9.23214099684292e+18\n",
      "Iteracion: 14 Error: 1.620617744244241e+43 Beta1: 1.335461456283324e+22 Beta0: 2.0852731890603742e+21\n",
      "Iteracion: 16 Error: 8.268022530208811e+47 Beta1: 3.0164205364318357e+24 Beta0: 4.710028014629614e+23\n",
      "Iteracion: 18 Error: 4.2181567370113103e+52 Beta1: 6.813220111893182e+26 Beta0: 1.0638588754210767e+26\n"
     ]
    }
   ],
   "source": [
    "# epochs \n",
    "num_steps = 20\n",
    "\n",
    "with tf.Session(graph = grafoInicial) as session3:\n",
    "    #Inicilizacion de variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Inicializado')\n",
    "    writer = tf.summary.FileWriter('./graphs3', session3.graph)\n",
    "    for step in range(num_steps): \n",
    "        # sesion que ejecuta los nodos y envia informacion con feed_dict al nodo del learning rate\n",
    "        er, opti = session3.run([error, optimizador],feed_dict={ph_learningrate:0.4})\n",
    "        summary = session3.run(Summary1st)\n",
    "        writer.add_summary(summary, step)\n",
    "        if (step % 2 == 0):\n",
    "            print(\"Iteracion:\", step, \"Error:\", er, \"Beta1:\", session3.run(est1), \"Beta0:\", session3.run(est0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuarta Sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializado\n",
      "Iteracion: 0 Error: 19409722053.22175 Beta1: 95035.81390410948 Beta0: 14447.222191780822\n",
      "Iteracion: 2 Error: 427871038356.74615 Beta1: 347767.9445346079 Beta0: 53130.32190068177\n",
      "Iteracion: 4 Error: 10097732530878.422 Beta1: 1576990.5372376184 Beta0: 244294.6587574294\n",
      "Iteracion: 6 Error: 239018887157757.66 Beta1: 7557388.730089376 Beta0: 1177343.1753135358\n",
      "Iteracion: 8 Error: 5658421922992863.0 Beta1: 36654916.36768675 Beta0: 5720050.929573888\n",
      "Iteracion: 10 Error: 1.3395555936240506e+17 Beta1: 178230208.48798063 Beta0: 27825747.307324126\n",
      "Iteracion: 12 Error: 3.1712191391983324e+18 Beta1: 867072721.9202883 Beta0: 135385182.1586864\n",
      "Iteracion: 14 Error: 7.50743826647455e+19 Beta1: 4218676283.4332314 Beta0: 658724815.84312\n",
      "Iteracion: 16 Error: 1.7772858598969686e+21 Beta1: 20526101271.66503 Beta0: 3205067585.375658\n",
      "Iteracion: 18 Error: 4.2074871823433864e+22 Beta1: 99870841954.2373 Beta0: 15594451783.31992\n"
     ]
    }
   ],
   "source": [
    "# epochs \n",
    "num_steps = 20\n",
    "\n",
    "with tf.Session(graph = grafoInicial) as session4:\n",
    "    #Inicilizacion de variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Inicializado')\n",
    "    writer = tf.summary.FileWriter('./graphs4', session4.graph)\n",
    "    for step in range(num_steps): \n",
    "        # sesion que ejecuta los nodos y envia informacion con feed_dict al nodo del learning rate\n",
    "        er, opti = session4.run([error, optimizador],feed_dict={ph_learningrate:0.08})\n",
    "        summary = session4.run(Summary1st)\n",
    "        writer.add_summary(summary, step)\n",
    "        if (step % 2 == 0):\n",
    "            print(\"Iteracion:\", step, \"Error:\", er, \"Beta1:\", session4.run(est1), \"Beta0:\", session4.run(est0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quinta Sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializado\n",
      "Iteracion: 0 Error: 19409722053.22175 Beta1: 19007.1627808219 Beta0: 2889.4444383561645\n",
      "Iteracion: 2 Error: 1692717920.729602 Beta1: 28293.222901513873 Beta0: 4182.70020983109\n",
      "Iteracion: 4 Error: 1398222565.9951367 Beta1: 29509.72899052926 Beta0: 4216.162627106623\n",
      "Iteracion: 6 Error: 1392606374.9093754 Beta1: 29687.119692413442 Beta0: 4087.608068732467\n",
      "Iteracion: 8 Error: 1391782214.470255 Beta1: 29730.676277016206 Beta0: 3938.3924651157217\n",
      "Iteracion: 10 Error: 1391039721.833484 Beta1: 29756.968208974962 Beta0: 3786.7173443925567\n",
      "Iteracion: 12 Error: 1390300789.3111522 Beta1: 29781.005715504754 Beta0: 3634.926139607562\n",
      "Iteracion: 14 Error: 1389564115.1480346 Beta1: 29804.721650454238 Beta0: 3483.320301335709\n",
      "Iteracion: 16 Error: 1388829671.1032403 Beta1: 29828.364946988328 Beta0: 3331.9383427672706\n",
      "Iteracion: 18 Error: 1388097450.0717597 Beta1: 29851.96770652698 Beta0: 3180.7849201657164\n"
     ]
    }
   ],
   "source": [
    "# epochs \n",
    "num_steps = 20\n",
    "\n",
    "with tf.Session(graph = grafoInicial) as session5:\n",
    "    #Inicilizacion de variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Inicializado')\n",
    "    writer = tf.summary.FileWriter('./graphs5', session5.graph)\n",
    "    for step in range(num_steps): \n",
    "        # sesion que ejecuta los nodos y envia informacion con feed_dict al nodo del learning rate\n",
    "        er, opti = session5.run([error, optimizador],feed_dict={ph_learningrate:0.016})\n",
    "        summary = session5.run(Summary1st)\n",
    "        writer.add_summary(summary, step)\n",
    "        if (step % 2 == 0):\n",
    "            print(\"Iteracion:\", step, \"Error:\", er, \"Beta1:\", session5.run(est1), \"Beta0:\", session5.run(est0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sexta Sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializado\n",
      "Iteracion: 0 Error: 19409722053.22175 Beta1: 3801.4325561643795 Beta0: 577.8888876712329\n",
      "Iteracion: 2 Error: 11799490087.577244 Beta1: 10005.289566424328 Beta0: 1515.2239042581946\n",
      "Iteracion: 4 Error: 7403995525.092175 Beta1: 14721.239249571898 Beta0: 2220.237254894668\n",
      "Iteracion: 6 Error: 4865232463.641308 Beta1: 18306.40972943273 Beta0: 2748.6931594839843\n",
      "Iteracion: 8 Error: 3398859301.158277 Beta1: 21032.211008549144 Beta0: 3142.9712734198756\n",
      "Iteracion: 10 Error: 2551864936.7468405 Beta1: 23104.909086641164 Beta0: 3435.2792593468553\n",
      "Iteracion: 12 Error: 2062604371.5923862 Beta1: 24681.261865955646 Beta0: 3650.094275385715\n",
      "Iteracion: 14 Error: 1779959663.3890643 Beta1: 25880.40211658262 Beta0: 3806.018455788852\n",
      "Iteracion: 16 Error: 1616649829.9175577 Beta1: 26792.86828481314 Beta0: 3917.189037938364\n",
      "Iteracion: 18 Error: 1522264114.2392185 Beta1: 27487.46772108156 Beta0: 3994.350029757419\n"
     ]
    }
   ],
   "source": [
    "# epochs \n",
    "num_steps = 20\n",
    "\n",
    "with tf.Session(graph = grafoInicial) as session6:\n",
    "    #Inicilizacion de variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Inicializado')\n",
    "    writer = tf.summary.FileWriter('./graphs6', session6.graph)\n",
    "    for step in range(num_steps): \n",
    "        # sesion que ejecuta los nodos y envia informacion con feed_dict al nodo del learning rate\n",
    "        er, opti = session6.run([error, optimizador],feed_dict={ph_learningrate:0.0032})\n",
    "        summary = session6.run(Summary1st)\n",
    "        writer.add_summary(summary, step)\n",
    "        if (step % 2 == 0):\n",
    "            print(\"Iteracion:\", step, \"Error:\", er, \"Beta1:\", session6.run(est1), \"Beta0:\", session6.run(est0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l_rate1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-4bbe65510f88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0ml_rate1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_rate2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_rate3\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_rate4\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.08\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_rate5\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.016\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_rate6\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.0032\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'l_rate1' is not defined"
     ]
    }
   ],
   "source": [
    "feed_dict={l_rate1: 10, l_rate2: 2, l_rate3: 0.4, l_rate4: 0.08, l_rate5: 0.016, l_rate6: 0.0032}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
