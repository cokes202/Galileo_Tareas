{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.08500e+05 7.00000e+00 8.56000e+02 8.00000e+00 2.00300e+03 6.50000e+01]\n",
      " [1.81500e+05 6.00000e+00 1.26200e+03 6.00000e+00 1.97600e+03 8.00000e+01]\n",
      " [2.23500e+05 7.00000e+00 9.20000e+02 6.00000e+00 2.00100e+03 6.80000e+01]\n",
      " ...\n",
      " [2.66500e+05 7.00000e+00 1.18800e+03 9.00000e+00 1.94100e+03 6.60000e+01]\n",
      " [1.42125e+05 5.00000e+00 1.07800e+03 5.00000e+00 1.95000e+03 6.80000e+01]\n",
      " [1.47500e+05 5.00000e+00 1.25600e+03 6.00000e+00 1.96500e+03 7.50000e+01]]\n",
      "<class 'numpy.ndarray'>\n",
      "(1460, 6)\n"
     ]
    }
   ],
   "source": [
    "## Importar datos desde el dataset.\n",
    "dataset = \"proyecto_training_data.npy\"\n",
    "data = np.load(dataset)\n",
    "print(data) \n",
    "print(type(data))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80% de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0850e+05 7.0000e+00 8.5600e+02 8.0000e+00 2.0030e+03 6.5000e+01]\n",
      " [1.8150e+05 6.0000e+00 1.2620e+03 6.0000e+00 1.9760e+03 8.0000e+01]\n",
      " [2.2350e+05 7.0000e+00 9.2000e+02 6.0000e+00 2.0010e+03 6.8000e+01]\n",
      " ...\n",
      " [2.3317e+05 7.0000e+00 1.5020e+03 7.0000e+00 2.0090e+03 7.9000e+01]\n",
      " [2.4535e+05 8.0000e+00 1.6940e+03 7.0000e+00 2.0080e+03 6.4000e+01]\n",
      " [1.7300e+05 6.0000e+00 9.5900e+02 7.0000e+00 2.0000e+03 5.8000e+01]]\n",
      "(Filas , Columnas) = (1168, 6)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "## Slicing al dataset\n",
    "trainingdata = data [:1168,]\n",
    "\n",
    "print(trainingdata)\n",
    "print(\"(Filas , Columnas) =\", trainingdata.shape) \n",
    "print(type(trainingdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20% de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.35000e+05 6.00000e+00 1.23600e+03 7.00000e+00 1.93500e+03 1.20000e+02]\n",
      " [6.25000e+05 1.00000e+01 1.83100e+03 1.00000e+01 1.99500e+03 1.18000e+02]\n",
      " [1.71000e+05 6.00000e+00 1.11800e+03 6.00000e+00 1.97700e+03 7.60000e+01]\n",
      " ...\n",
      " [2.66500e+05 7.00000e+00 1.18800e+03 9.00000e+00 1.94100e+03 6.60000e+01]\n",
      " [1.42125e+05 5.00000e+00 1.07800e+03 5.00000e+00 1.95000e+03 6.80000e+01]\n",
      " [1.47500e+05 5.00000e+00 1.25600e+03 6.00000e+00 1.96500e+03 7.50000e+01]]\n",
      "(Filas , Columnas) = (292, 6)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "## Slicing al dataset \n",
    "dataprueba = data [1168:,]\n",
    "\n",
    "print(dataprueba)\n",
    "print(\"(Filas , Columnas) =\", dataprueba.shape)\n",
    "print(type(dataprueba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de los datos por Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208500. 181500. 223500. ... 233170. 245350. 173000.] de tipo  <class 'numpy.ndarray'> de rango  1 de la forma  (1168,)\n",
      "[7. 6. 7. ... 7. 8. 6.] de tipo  <class 'numpy.ndarray'> de rango  1 de la forma  (1168,)\n"
     ]
    }
   ],
   "source": [
    "# Extracción por columnas del 80%\n",
    "\n",
    "saleprice=trainingdata[:,0]\n",
    "quality=trainingdata[:,1]\n",
    "\n",
    "print(saleprice,\"de tipo \", type(saleprice),\"de rango \",saleprice.ndim, \"de la forma \",saleprice.shape)\n",
    "print(quality,\"de tipo \", type(quality),\"de rango \",quality.ndim, \"de la forma \",quality.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracción por Columnas del 20%\n",
    "\n",
    "saleprice20=dataprueba[:,0]\n",
    "quality20=dataprueba[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Las dos variables con mayor poder predictivo (Mayor correlación)\n",
    "1. La variable Quality tiene un coeficiente de correlación de 0.79\n",
    "2. La variable Square Feet tiene un coeficiente de correlación de 0.61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que cada extracción de columna era un vector de 1168 filas, ahora lo convertiremos en una matriz de (1168,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[208500.]\n",
      " [181500.]\n",
      " [223500.]\n",
      " ...\n",
      " [233170.]\n",
      " [245350.]\n",
      " [173000.]] de tipo  <class 'numpy.ndarray'> de rango  2 de la forma  (1168, 1)\n",
      "[[7.]\n",
      " [6.]\n",
      " [7.]\n",
      " ...\n",
      " [7.]\n",
      " [8.]\n",
      " [6.]] de tipo  <class 'numpy.ndarray'> de rango  2 de la forma  (1168, 1)\n"
     ]
    }
   ],
   "source": [
    "saleprice=np.reshape(saleprice,(1168,1)) \n",
    "quality=np.reshape(quality,(1168,1)) \n",
    "\n",
    "print(saleprice,\"de tipo \", type(saleprice),\"de rango \",saleprice.ndim, \"de la forma \",saleprice.shape)\n",
    "print(quality,\"de tipo \", type(quality),\"de rango \",quality.ndim, \"de la forma \",quality.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que cada extracción de columna era un vector de 292 filas, ahora lo convertiremos en una matriz de (292,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[235000.]\n",
      " [625000.]\n",
      " [171000.]\n",
      " [163000.]\n",
      " [171900.]\n",
      " [200500.]\n",
      " [239000.]\n",
      " [285000.]\n",
      " [119500.]\n",
      " [115000.]\n",
      " [154900.]\n",
      " [ 93000.]\n",
      " [250000.]\n",
      " [392500.]\n",
      " [745000.]\n",
      " [120000.]\n",
      " [186700.]\n",
      " [104900.]\n",
      " [ 95000.]\n",
      " [262000.]\n",
      " [195000.]\n",
      " [189000.]\n",
      " [168000.]\n",
      " [174000.]\n",
      " [125000.]\n",
      " [165000.]\n",
      " [158000.]\n",
      " [176000.]\n",
      " [219210.]\n",
      " [144000.]\n",
      " [178000.]\n",
      " [148000.]\n",
      " [116050.]\n",
      " [197900.]\n",
      " [117000.]\n",
      " [213000.]\n",
      " [153500.]\n",
      " [271900.]\n",
      " [107000.]\n",
      " [200000.]\n",
      " [140000.]\n",
      " [290000.]\n",
      " [189000.]\n",
      " [164000.]\n",
      " [113000.]\n",
      " [145000.]\n",
      " [134500.]\n",
      " [125000.]\n",
      " [112000.]\n",
      " [229456.]\n",
      " [ 80500.]\n",
      " [ 91500.]\n",
      " [115000.]\n",
      " [134000.]\n",
      " [143000.]\n",
      " [137900.]\n",
      " [184000.]\n",
      " [145000.]\n",
      " [214000.]\n",
      " [147000.]\n",
      " [367294.]\n",
      " [127000.]\n",
      " [190000.]\n",
      " [132500.]\n",
      " [101800.]\n",
      " [142000.]\n",
      " [130000.]\n",
      " [138887.]\n",
      " [175500.]\n",
      " [195000.]\n",
      " [142500.]\n",
      " [265900.]\n",
      " [224900.]\n",
      " [248328.]\n",
      " [170000.]\n",
      " [465000.]\n",
      " [230000.]\n",
      " [178000.]\n",
      " [186500.]\n",
      " [169900.]\n",
      " [129500.]\n",
      " [119000.]\n",
      " [244000.]\n",
      " [171750.]\n",
      " [130000.]\n",
      " [294000.]\n",
      " [165400.]\n",
      " [127500.]\n",
      " [301500.]\n",
      " [ 99900.]\n",
      " [190000.]\n",
      " [151000.]\n",
      " [181000.]\n",
      " [128900.]\n",
      " [161500.]\n",
      " [180500.]\n",
      " [181000.]\n",
      " [183900.]\n",
      " [122000.]\n",
      " [378500.]\n",
      " [381000.]\n",
      " [144000.]\n",
      " [260000.]\n",
      " [185750.]\n",
      " [137000.]\n",
      " [177000.]\n",
      " [139000.]\n",
      " [137000.]\n",
      " [162000.]\n",
      " [197900.]\n",
      " [237000.]\n",
      " [ 68400.]\n",
      " [227000.]\n",
      " [180000.]\n",
      " [150500.]\n",
      " [139000.]\n",
      " [169000.]\n",
      " [132500.]\n",
      " [143000.]\n",
      " [190000.]\n",
      " [278000.]\n",
      " [281000.]\n",
      " [180500.]\n",
      " [119500.]\n",
      " [107500.]\n",
      " [162900.]\n",
      " [115000.]\n",
      " [138500.]\n",
      " [155000.]\n",
      " [140000.]\n",
      " [160000.]\n",
      " [154000.]\n",
      " [225000.]\n",
      " [177500.]\n",
      " [290000.]\n",
      " [232000.]\n",
      " [130000.]\n",
      " [325000.]\n",
      " [202500.]\n",
      " [138000.]\n",
      " [147000.]\n",
      " [179200.]\n",
      " [335000.]\n",
      " [203000.]\n",
      " [302000.]\n",
      " [333168.]\n",
      " [119000.]\n",
      " [206900.]\n",
      " [295493.]\n",
      " [208900.]\n",
      " [275000.]\n",
      " [111000.]\n",
      " [156500.]\n",
      " [ 72500.]\n",
      " [190000.]\n",
      " [ 82500.]\n",
      " [147000.]\n",
      " [ 55000.]\n",
      " [ 79000.]\n",
      " [130500.]\n",
      " [256000.]\n",
      " [176500.]\n",
      " [227000.]\n",
      " [132500.]\n",
      " [100000.]\n",
      " [125500.]\n",
      " [125000.]\n",
      " [167900.]\n",
      " [135000.]\n",
      " [ 52500.]\n",
      " [200000.]\n",
      " [128500.]\n",
      " [123000.]\n",
      " [155000.]\n",
      " [228500.]\n",
      " [177000.]\n",
      " [155835.]\n",
      " [108500.]\n",
      " [262500.]\n",
      " [283463.]\n",
      " [215000.]\n",
      " [122000.]\n",
      " [200000.]\n",
      " [171000.]\n",
      " [134900.]\n",
      " [410000.]\n",
      " [235000.]\n",
      " [170000.]\n",
      " [110000.]\n",
      " [149900.]\n",
      " [177500.]\n",
      " [315000.]\n",
      " [189000.]\n",
      " [260000.]\n",
      " [104900.]\n",
      " [156932.]\n",
      " [144152.]\n",
      " [216000.]\n",
      " [193000.]\n",
      " [127000.]\n",
      " [144000.]\n",
      " [232000.]\n",
      " [105000.]\n",
      " [165500.]\n",
      " [274300.]\n",
      " [466500.]\n",
      " [250000.]\n",
      " [239000.]\n",
      " [ 91000.]\n",
      " [117000.]\n",
      " [ 83000.]\n",
      " [167500.]\n",
      " [ 58500.]\n",
      " [237500.]\n",
      " [157000.]\n",
      " [112000.]\n",
      " [105000.]\n",
      " [125500.]\n",
      " [250000.]\n",
      " [136000.]\n",
      " [377500.]\n",
      " [131000.]\n",
      " [235000.]\n",
      " [124000.]\n",
      " [123000.]\n",
      " [163000.]\n",
      " [246578.]\n",
      " [281213.]\n",
      " [160000.]\n",
      " [137500.]\n",
      " [138000.]\n",
      " [137450.]\n",
      " [120000.]\n",
      " [193000.]\n",
      " [193879.]\n",
      " [282922.]\n",
      " [105000.]\n",
      " [275000.]\n",
      " [133000.]\n",
      " [112000.]\n",
      " [125500.]\n",
      " [215000.]\n",
      " [230000.]\n",
      " [140000.]\n",
      " [ 90000.]\n",
      " [257000.]\n",
      " [207000.]\n",
      " [175900.]\n",
      " [122500.]\n",
      " [340000.]\n",
      " [124000.]\n",
      " [223000.]\n",
      " [179900.]\n",
      " [127500.]\n",
      " [136500.]\n",
      " [274970.]\n",
      " [144000.]\n",
      " [142000.]\n",
      " [271000.]\n",
      " [140000.]\n",
      " [119000.]\n",
      " [182900.]\n",
      " [192140.]\n",
      " [143750.]\n",
      " [ 64500.]\n",
      " [186500.]\n",
      " [160000.]\n",
      " [174000.]\n",
      " [120500.]\n",
      " [394617.]\n",
      " [149700.]\n",
      " [197000.]\n",
      " [191000.]\n",
      " [149300.]\n",
      " [310000.]\n",
      " [121000.]\n",
      " [179600.]\n",
      " [129000.]\n",
      " [157900.]\n",
      " [240000.]\n",
      " [112000.]\n",
      " [ 92000.]\n",
      " [136000.]\n",
      " [287090.]\n",
      " [145000.]\n",
      " [ 84500.]\n",
      " [185000.]\n",
      " [175000.]\n",
      " [210000.]\n",
      " [266500.]\n",
      " [142125.]\n",
      " [147500.]] de tipo  <class 'numpy.ndarray'> de rango  2 de la forma  (292, 1)\n",
      "[[ 6.]\n",
      " [10.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 9.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 9.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 9.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 3.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [10.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]] de tipo  <class 'numpy.ndarray'> de rango  2 de la forma  (292, 1)\n"
     ]
    }
   ],
   "source": [
    "# Extracción por Columnas del 20%\n",
    "\n",
    "saleprice20=np.reshape(saleprice20,(292,1)) \n",
    "quality20=np.reshape(quality20,(292,1)) \n",
    "\n",
    "print(saleprice20,\"de tipo \", type(saleprice20),\"de rango \",saleprice20.ndim, \"de la forma \",saleprice20.shape)\n",
    "print(quality20,\"de tipo \", type(quality20),\"de rango \",quality20.ndim, \"de la forma \",quality20.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del Gráfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Coke Garcia\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "grafoInicial = tf.Graph()\n",
    "with grafoInicial.as_default():\n",
    "    # cargando datos como constantes \n",
    "    trainingY = tf.constant(saleprice)\n",
    "    trainingX = tf.constant(quality)\n",
    "    pruebaY = tf.constant(saleprice20)\n",
    "    pruebaX = tf.constant(quality20)\n",
    "    \n",
    "    #placeholder:\n",
    "    ph_learningrate = tf.placeholder(dtype = tf.float64)    \n",
    "  \n",
    "    #Parametros beta1 y beta2:\n",
    "    #Variables\n",
    "    #Estimadores = tf.Variable(np.array([[0],[0]]))\n",
    "    est0 = tf.Variable(0.0, name = \"b0\", dtype = tf.float64)\n",
    "    est1 = tf.Variable(0.0, name = \"b1\", dtype = tf.float64)     \n",
    "    \n",
    "    #Parte de Entrenamiento\n",
    "    #yhat = tf.matmul(trainingX, estimadores)\n",
    "    #Hipotesis\n",
    "    yhat = tf.add(tf.multiply(trainingX, est1), est0)\n",
    "    \n",
    "    #Costo\n",
    "    error = (tf.reduce_mean(tf.pow(trainingY-yhat,2)))*.5\n",
    "    \n",
    "    ##para tensorboard\n",
    "    recuento = tf.summary.scalar(name='Primer_Recuento_Escalar', tensor=error)\n",
    "    \n",
    "    # gradient descent un nodo mas del grafo\n",
    "    optimizador = tf.train.GradientDescentOptimizer(ph_learningrate).minimize(error) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"GRAFO.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primera Sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializado\n",
      "Iteracion: 0 Error: 19409722053.22175 Beta1: 11879476.738013685 Beta0: 1805902.7739726028\n",
      "Iteracion: 2 Error: 4.5991659790119325e+20 Beta1: 1892177310679.6533 Beta0: 295456331982.5073\n",
      "Iteracion: 4 Error: 1.1741538548192451e+31 Beta1: 3.02332463745082e+17 Beta0: 4.720808510516164e+16\n",
      "Iteracion: 6 Error: 2.9975810420448657e+41 Beta1: 4.830674176285755e+22 Beta0: 7.542917317082002e+21\n",
      "Iteracion: 8 Error: 7.652738239325503e+51 Beta1: 7.718460898434383e+27 Beta0: 1.2052088434742129e+27\n",
      "Iteracion: 10 Error: 1.9537220758403224e+62 Beta1: 1.2332572321502991e+33 Beta0: 1.925685110055494e+32\n",
      "Iteracion: 12 Error: 4.987796302781102e+72 Beta1: 1.970500881800828e+38 Beta0: 3.076863535451501e+37\n",
      "Iteracion: 14 Error: 1.2733700594203426e+83 Beta1: 3.148470265532254e+43 Beta0: 4.9162187350133154e+42\n",
      "Iteracion: 16 Error: 3.250877160568992e+93 Beta1: 5.030632112116291e+48 Beta0: 7.855144166135146e+47\n",
      "Iteracion: 18 Error: 8.299395949296999e+103 Beta1: 8.037954089802256e+53 Beta0: 1.2550965121083018e+53\n"
     ]
    }
   ],
   "source": [
    "# epochs \n",
    "num_steps = 20\n",
    "\n",
    "with tf.Session(graph = grafoInicial) as session:\n",
    "    #Inicilizacion de variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Inicializado')\n",
    "    writer = tf.summary.FileWriter('./graphs', session.graph)\n",
    "    for step in range(num_steps): \n",
    "        # sesion que ejecuta los nodos y envia informacion con feed_dict al nodo del learning rate\n",
    "        er, opti = session.run([error, optimizador],feed_dict={ph_learningrate:10.0})\n",
    "        summary = session.run(recuento)\n",
    "        writer.add_summary(summary, step)\n",
    "        if (step % 2 == 0):\n",
    "            print(\"Iteracion:\", step, \"Error:\", er, \"Beta1:\", session.run(est1), \"Beta0:\", session.run(est0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda Sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializado\n",
      "Iteracion: 0 Error: 19409722053.22175 Beta1: 1187947.6738013686 Beta0: 180590.27739726027\n",
      "Iteracion: 2 Error: 4.1987369532118696e+16 Beta1: 1767255346.729938 Beta0: 275936297.83559537\n",
      "Iteracion: 4 Error: 9.785976057427764e+22 Beta1: 2697952202783.967 Beta0: 421275138232.01025\n",
      "Iteracion: 6 Error: 2.280812814548885e+29 Beta1: 4118859651756539.0 Beta0: 643144552057379.6\n",
      "Iteracion: 8 Error: 5.31587964704039e+35 Beta1: 6.288104370696646e+18 Beta0: 9.818640135612266e+17\n",
      "Iteracion: 10 Error: 1.2389695568861071e+42 Beta1: 9.59980672326122e+21 Beta0: 1.4989739678365697e+21\n",
      "Iteracion: 12 Error: 2.8876604904800966e+48 Beta1: 1.4655655137251198e+25 Beta0: 2.2884258158133876e+24\n",
      "Iteracion: 14 Error: 6.730256657182867e+54 Beta1: 2.237422415824094e+28 Beta0: 3.4936515422208277e+27\n",
      "Iteracion: 16 Error: 1.5686177381615557e+61 Beta1: 3.4157866161219335e+31 Beta0: 5.33362323310606e+30\n",
      "Iteracion: 18 Error: 3.655969948559207e+67 Beta1: 5.214749849808942e+34 Beta0: 8.14263713737335e+33\n"
     ]
    }
   ],
   "source": [
    "# epochs \n",
    "num_steps = 20\n",
    "\n",
    "with tf.Session(graph = grafoInicial) as session2:\n",
    "    #Inicilizacion de variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Inicializado')\n",
    "    writer = tf.summary.FileWriter('./graphs2', session2.graph)\n",
    "    for step in range(num_steps): \n",
    "        # sesion que ejecuta los nodos y envia informacion con feed_dict al nodo del learning rate\n",
    "        er, opti = session2.run([error, optimizador],feed_dict={ph_learningrate:1})\n",
    "        summary = session2.run(recuento)\n",
    "        writer.add_summary(summary, step)\n",
    "        if (step % 2 == 0):\n",
    "            print(\"Iteracion:\", step, \"Error:\", er, \"Beta1:\", session2.run(est1), \"Beta0:\", session2.run(est0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tercera Sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializado\n",
      "Iteracion: 0 Error: 19409722053.22175 Beta1: 118794.76738013687 Beta0: 18059.02773972603\n",
      "Iteracion: 2 Error: 1474761375440.7397 Beta1: 835574.1204399086 Beta0: 129007.73751476406\n",
      "Iteracion: 4 Error: 120502547628807.03 Beta1: 7316617.37917742 Beta0: 1140033.9272875148\n",
      "Iteracion: 6 Error: 9855311023202318.0 Beta1: 65927149.82447075 Beta0: 10290894.279479643\n",
      "Iteracion: 8 Error: 8.060264865517955e+17 Beta1: 595973959.8531418 Beta0: 93054777.7484751\n",
      "Iteracion: 10 Error: 6.592169281403146e+19 Beta1: 5389483976.492045 Beta0: 841542527.2905977\n",
      "Iteracion: 12 Error: 5.391472443170872e+21 Beta1: 48739887758.78403 Beta0: 7610545250.360823\n",
      "Iteracion: 14 Error: 4.4094703678292546e+23 Beta1: 440781950043.9867 Beta0: 68826448213.13431\n",
      "Iteracion: 16 Error: 3.606330020177906e+25 Beta1: 3986238637613.265 Beta0: 622436267995.6798\n",
      "Iteracion: 18 Error: 2.949473548869538e+27 Beta1: 36049795934814.13 Beta0: 5629040992611.314\n"
     ]
    }
   ],
   "source": [
    "# epochs \n",
    "num_steps = 20\n",
    "\n",
    "with tf.Session(graph = grafoInicial) as session3:\n",
    "    #Inicilizacion de variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Inicializado')\n",
    "    writer = tf.summary.FileWriter('./graphs3', session3.graph)\n",
    "    for step in range(num_steps): \n",
    "        # sesion que ejecuta los nodos y envia informacion con feed_dict al nodo del learning rate\n",
    "        er, opti = session3.run([error, optimizador],feed_dict={ph_learningrate:0.1})\n",
    "        summary = session3.run(recuento)\n",
    "        writer.add_summary(summary, step)\n",
    "        if (step % 2 == 0):\n",
    "            print(\"Iteracion:\", step, \"Error:\", er, \"Beta1:\", session3.run(est1), \"Beta0:\", session3.run(est0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuarta Sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializado\n",
      "Iteracion: 0 Error: 19409722053.22175 Beta1: 11879.476738013685 Beta0: 1805.9027739726027\n",
      "Iteracion: 2 Error: 3717770447.2485785 Beta1: 23272.603178250207 Beta0: 3486.900249135218\n",
      "Iteracion: 4 Error: 1693499585.3201845 Beta1: 27373.779446738263 Beta0: 4029.379713620872\n",
      "Iteracion: 6 Error: 1432013147.1072404 Beta1: 28856.186135910168 Beta0: 4163.040776370932\n",
      "Iteracion: 8 Error: 1397881894.3230965 Beta1: 29398.1041799059 Beta0: 4149.940649695315\n",
      "Iteracion: 10 Error: 1393074454.206566 Beta1: 29602.255186377413 Beta0: 4084.191974002789\n",
      "Iteracion: 12 Error: 1392049808.282319 Beta1: 29685.094778536117 Beta0: 3999.593398886302\n",
      "Iteracion: 14 Error: 1391513812.4658086 Beta1: 29724.358746045444 Beta0: 3908.2829900844226\n",
      "Iteracion: 16 Error: 1391041604.3933318 Beta1: 29747.964377854983 Beta0: 3814.6198405871837\n",
      "Iteracion: 18 Error: 1390578386.1651592 Beta1: 29765.937627907548 Beta0: 3720.169378324098\n"
     ]
    }
   ],
   "source": [
    "# epochs \n",
    "num_steps = 20\n",
    "\n",
    "with tf.Session(graph = grafoInicial) as session4:\n",
    "    #Inicilizacion de variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Inicializado')\n",
    "    writer = tf.summary.FileWriter('./graphs4', session4.graph)\n",
    "    for step in range(num_steps): \n",
    "        # sesion que ejecuta los nodos y envia informacion con feed_dict al nodo del learning rate\n",
    "        er, opti = session4.run([error, optimizador],feed_dict={ph_learningrate:0.01})\n",
    "        summary = session4.run(recuento)\n",
    "        writer.add_summary(summary, step)\n",
    "        if (step % 2 == 0):\n",
    "            print(\"Iteracion:\", step, \"Error:\", er, \"Beta1:\", session4.run(est1), \"Beta0:\", session4.run(est0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quinta Sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializado\n",
      "Iteracion: 0 Error: 19409722053.22175 Beta1: 1187.9476738013686 Beta0: 180.59027739726028\n",
      "Iteracion: 2 Error: 16691037688.98972 Beta1: 3423.0270258274136 Beta0: 519.7836368482164\n",
      "Iteracion: 4 Error: 14382623015.887161 Beta1: 5482.682230497807 Beta0: 831.5860993870335\n",
      "Iteracion: 6 Error: 12422564219.848372 Beta1: 7380.690953254501 Beta0: 1118.1489959296696\n",
      "Iteracion: 8 Error: 10758290902.950512 Beta1: 9129.748772377112 Beta0: 1381.4546935229175\n",
      "Iteracion: 10 Error: 9345166068.111794 Beta1: 10741.554165269808 Beta0: 1623.3298656357094\n",
      "Iteracion: 12 Error: 8145288889.255076 Beta1: 12226.886819991123 Beta0: 1845.4577202120292\n",
      "Iteracion: 14 Error: 7126478155.473641 Beta1: 13595.679796256918 Beta0: 2049.3892673420282\n",
      "Iteracion: 16 Error: 6261409123.678336 Beta1: 14857.086018974107 Beta0: 2236.5537019789867\n",
      "Iteracion: 18 Error: 5526880628.846098 Beta1: 16019.539549423798 Beta0: 2408.267971205734\n"
     ]
    }
   ],
   "source": [
    "# epochs \n",
    "num_steps = 20\n",
    "\n",
    "with tf.Session(graph = grafoInicial) as session5:\n",
    "    #Inicilizacion de variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Inicializado')\n",
    "    writer = tf.summary.FileWriter('./graphs5', session5.graph)\n",
    "    for step in range(num_steps): \n",
    "        # sesion que ejecuta los nodos y envia informacion con feed_dict al nodo del learning rate\n",
    "        er, opti = session5.run([error, optimizador],feed_dict={ph_learningrate:0.001})\n",
    "        summary = session5.run(recuento)\n",
    "        writer.add_summary(summary, step)\n",
    "        if (step % 2 == 0):\n",
    "            print(\"Iteracion:\", step, \"Error:\", er, \"Beta1:\", session5.run(est1), \"Beta0:\", session5.run(est0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sexta Sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializado\n",
      "Iteracion: 0 Error: 19409722053.22175 Beta1: 118.79476738013686 Beta0: 18.059027739726027\n",
      "Iteracion: 2 Error: 19122686627.97568 Beta1: 354.95898445942515 Beta0: 53.9545321511267\n",
      "Iteracion: 4 Error: 18840224439.06416 Beta1: 589.2354492233663 Beta0: 89.55528037486923\n",
      "Iteracion: 6 Error: 18562262621.50268 Beta1: 821.6392607438453 Beta0: 124.86363007455056\n",
      "Iteracion: 8 Error: 18288729471.258484 Beta1: 1052.185397323649 Beta0: 159.88192005612413\n",
      "Iteracion: 10 Error: 18019554426.753 Beta1: 1280.8887174624338 Beta0: 194.61247041873187\n",
      "Iteracion: 12 Error: 17754668050.65932 Beta1: 1507.7639608149611 Beta0: 229.0575827043294\n",
      "Iteracion: 14 Error: 17494002011.989506 Beta1: 1732.8257491416753 Beta0: 263.2195400461148\n",
      "Iteracion: 16 Error: 17237489068.46755 Beta1: 1956.0885872516722 Beta0: 297.10060731577\n",
      "Iteracion: 18 Error: 16985063049.182821 Beta1: 2177.5668639381292 Beta0: 330.7030312695244\n"
     ]
    }
   ],
   "source": [
    "# epochs \n",
    "num_steps = 20\n",
    "\n",
    "with tf.Session(graph = grafoInicial) as session6:\n",
    "    #Inicilizacion de variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Inicializado')\n",
    "    writer = tf.summary.FileWriter('./graphs6', session6.graph)\n",
    "    for step in range(num_steps): \n",
    "        # sesion que ejecuta los nodos y envia informacion con feed_dict al nodo del learning rate\n",
    "        er, opti = session6.run([error, optimizador],feed_dict={ph_learningrate:0.0001})\n",
    "        summary = session6.run(recuento)\n",
    "        writer.add_summary(summary, step)\n",
    "        if (step % 2 == 0):\n",
    "            print(\"Iteracion:\", step, \"Error:\", er, \"Beta1:\", session6.run(est1), \"Beta0:\", session6.run(est0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
